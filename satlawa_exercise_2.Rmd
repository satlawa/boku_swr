---
title: "Statistics with R - Exercise 2"
author: "Philipp Satlawa - h0640348"
date: "04/12/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This document contains the answered questions of exercise 2 for the course "Statistics with R".

***
```{r}
# import necessary libraries
library("matrixStats")
library("readxl")
library("data.table")
library("ggplot2")
```


## Task 1 - Robustness of mean/median

1. Compare mean and median - Standard Normal Distribution
```{r}
# set seed
set.seed(640348)

# sample 100% from normal distribution
x <- rnorm(n = 50 * 1000, mean = 0, sd = 1)

# rearrange vector into matrix with 1000 rows (N) and 50 columns (n)
X <- matrix(x, ncol = 50)

# calculate the mean for every sample
xAvg <- rowMeans(X)

# calculate the median for every sample (row in matrix)
xMed <- rowMedians(X)

# plot the comparison between mean and median
par(mfrow = c(1, 2))
boxplot(xAvg, ylim = c(-0.55, 0.55) ,main = "mean estimation method")
boxplot(xMed, ylim = c(-0.55, 0.55), main = "median estimation method")
par(mfrow = c(1, 1))
```
In the case of sampling just from the Standard Normal Distribution, the mean estimation method provides a better fit to the underlying normally distributed population. Looking at the two box plots next to each other, we can clearly see that estimating the mean with the mean estimation method gives better results since the box is smaller and the whiskers are shorter than in the median estimation method. Hence, if I have the knowledge that the underlying population is normally distributed, I would choose the the mean estimation method for estimating the mean.


2. Compare mean and median - Standard Normal Distribution & Exponential Distribution
```{r}
# set seed
set.seed(640348)
# sample 90% from a Normal Distribution
x90 <- rnorm(n = 45 * 1000, mean = 0, sd = 1)

# set seed
set.seed(640348)
# sample 10% from Exponential Distribution
x10 <- rexp(n = 5 * 1000, rate = 0.2)

# rearrange vectors to matrices
x90 <- matrix(x90, ncol = 45)
x10 <- matrix(x10, ncol = 5)

# concatenate the two matrices into one matrix
X <- cbind(x90,x10)

# calculate the mean for every sample
xAvg <- rowMeans(X)

# calculate the median for every sample
xMed <- rowMedians(X)

# plot the comparison between mean and median
par(mfrow = c(1, 2))
boxplot(xAvg, ylim = c(-0.5, 1.5) ,main = "mean estimation method")
boxplot(xMed, ylim = c(-0.5, 1.5), main = "median estimation method")
par(mfrow = c(1, 1))
```
Compared to exclusively sampling from the Standard Normal Distribution, the sampling from the Standard Normal Distribution with the addition of the Exponential Distribution creates more extreme values in the dataset. The extreme values shift the estimation of the mean in a much greater magnitude, while using the mean estimation method than using the median estimation method. Examining at the box plots we can observe that the median estimation method provides a better estimate of the true mean, since 50th percentile is nearer to the true value the box is smaller and the whiskers are shorter than the mean estimation method.
If I assume that the underlying data contains outliers, I would choose the the median estimation method for estimating the mean.



## Task 2 - Estimation

1. Standard Cauchy Distribution with different sample sizes
```{r}
# set seed
set.seed(640348)
# sample 100 times from the Standard Cauchy distribution
cuy100 = rcauchy(100, location = 0, scale = 1)
# calculate mean
(mean(cuy100))
# calculate variance
(var(cuy100))

# set seed
set.seed(640348)
# sample 5000 times from the Standard Cauchy distribution
cuy5000 = rcauchy(5000, location = 0, scale = 1)
# calculate mean
(mean(cuy5000))
# calculate variance
(var(cuy5000))

# set seed
set.seed(640348)
# sample 100000 times from the Standard Cauchy distribution
cuy100000 = rcauchy(100000, location = 0, scale = 1)
# calculate mean
(mean(cuy100000))
# calculate variance
(var(cuy100000))
```


2. Observation of the Standard Cauchy Distribution depending on the sample size

Examining the calculated means and variance from the sample sizes 100, 5000 and 100000 we can not recognize any improvement in the accuracy of estimating the mean when increasing the sample size. This fits with the statement that the mean and the standard deviation of the Cauchy Distribution are undefined.


3. Plotting the standard normal and standard cauchy distribution
```{r}
# set seed
set.seed(640348)
# sample 100 times from the Standard Normal Distribution
norm100 <- rnorm(n = 100, mean = 0, sd = 1)

# set seed
set.seed(640348)
# sample 100 times from the Standard Cauchy Distribution
cuy100 <- rcauchy(n = 100, location = 0, scale = 1)

# plot the standard normal and standard cauchy distribution as a boxplot
par(mfrow = c(1,2))
boxplot(norm100, ylim = c(-10, 10) ,main = "Standard Normal Distribution") # ... function for normal boxplot
boxplot(cuy100, ylim = c(-10, 10) ,main = "Standard Cauchy Distribution") # ... function for cauchy boxplot
par(mfrow = c(1,1))
```
The Standard Cauchy Distribution has heavier tails hence the bell curve is much wider at the bottom compared to the Normal Distribution. This can be observed in the two box plots, while the Normal Distributions min/max are around +/-3, the min/max of the Standard Cauchy Distribution is around +6 /-10. Hence, the whiskers and the min max are much more wildly spread.



## Task 3 - Working with a real data set

1. Import data from different sources

  a. Import from file .Rdata (R specific file type)
```{r}
# load data from file
load("~/Documents/boku/statistics_with_R/ex_02/CO2.Rdata")
# convert data.frame to data.table
datCO2 <- setDT(dat)
# check if data was properly loaded
str(dat)
```

  b. Import from file .txt (tabulator separated values)
```{r}
# load data from txt-file
data_txt <- read.table(file = "~/Documents/boku/statistics_with_R/ex_02/CO2.txt", header = TRUE, dec = ".")
str(data_txt)
```

  c. Import from file .csv (comma separated values)
```{r}
# load data from csv-file
data_csv <- read.csv(file = "~/Documents/boku/statistics_with_R/ex_02/CO2.csv", header = TRUE)
str(data_csv)
```

  d. Import from file .xlsx (MS Excel specific file type)
```{r}
# list sheets in xlsx-file
excel_sheets("~/Documents/boku/statistics_with_R/ex_02/CO2.xlsx")
# load data from xlsx-file
data_xlsx <- read_excel("~/Documents/boku/statistics_with_R/ex_02/CO2.xlsx", sheet = "Sheet 1")
# print data structure
str(data_xlsx)
```


2. Set seed to the student id
```{r}
# prepare seed
set.seed(as.numeric(format(Sys.time(), "%H%M%S")))
# set student id
id <- 640348
# set seed with student id
set.seed(id)
```


3. Data exploration
```{r}
# show the data structure
str(dat)
# show the data summary
summary(dat)
```
The provided dataset contains 6 variables (columns) and 1619494 records (rows).
The variables have the following types:

* `unit` (unit abbreviation): categorical Factor with 2 levels
* `airpol` (chemical compound): categorical Factor with 11 levels
* `airemsect` (code for the sector): categorical Factor with 172 levels
* `geo` (country abbreviation): categorical Factor with 35 levels
* `time` (year): discrete numerical
* `values` (value): continuous numerical
  
The variable `values` has 5284 NA values and is the only variable that contains NA.


4. Select two countries randomly
```{r}
# create vector with all unique countries
geo_col <- datCO2[, unique(geo)]
# set seed with student id
set.seed(id)
# take 2 random samples
geo_c <- sample(geo_col, 2)
```


5. Filter data
```{r}
# filter data
datFilter <- datCO2[unit == "THS_T" & 
                      airpol == "GHG" & 
                      airemsect %in% c("CRF3", "CRF31", "CRF1A3") & 
                      geo %in% geo_c]
```


6. Remove columns/variables `unit` and `airpol`
```{r}
# remove variables
datFilter <- datFilter[, -c("unit", "airpol")]
```


7. Show number of observations per country
```{r}
# group by country and sum observations
datFilter[, .N, by = geo]
```
Both randomly picked countries have 84 observations each.


8. Rename variable `airemsect` and its categorical values
```{r}
# rename values in variable "airemsect"
datFilter[airemsect == "CRF1A3", airemsect := "Transport"]
datFilter[airemsect == "CRF3", airemsect := "Agriculture"]
datFilter[airemsect == "CRF31", airemsect := "Livestock"]
# rename variable "airemsect" to "sector"
setnames(datFilter, "airemsect", "sector")
```


9. Average greenhouse gas (GHG) emissions per sector
```{r}
# aggregate by variable "sector" and calculate the mean
datFilter[,.(mean(values)), by = sector, ]
```
The `sector` **Transport** produced on average the most greenhouse gas emissions.


10. Average GHG per sector and country
```{r}
# aggregate by variable "sector" and "geo" and calculate the mean
datFilter[,.(mean(values)), by = .(sector, geo)]
# calculate the difference in greenhouse gas emissions in the sector "Livestock"
datFilter[sector == "Livestock" & geo == geo_c[2], .(mean(values))] - 
  datFilter[sector == "Livestock" & geo == geo_c[1], .(mean(values))]
```
Country **LU** has 106 \*10³ tonnes of GHG higher on average greenhouse gas emissions in the `sector` **Livestock** than country **IS**.


11. Production of GHG by the sector **Livestock** per country for the period 2000-2017
```{r}
datFilter[sector == "Livestock" & time %between% c(2000, 2017), .(sum(values)), by = .(geo)]
```
The sector "Livestock" produced 6484 \*10³ tonnes of GHG in the country **IS** and  8389 \*10³ tonnes of GHG in the country **LU** for the period 2000-2017.


12. Plotting the GHG emissions of ”Transportation” sector for both countries
```{r}
ggplot(data=datFilter[sector == "Transport"], aes(x=time, y=values, color=geo)) + 
  geom_line() + xlab("Year") + ylab("Thousand tonnes of GHG")
```